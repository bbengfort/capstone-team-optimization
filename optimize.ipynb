{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Team Optimization \n",
    "\n",
    "**Automatic selection of Capstone teams based on preferences.**\n",
    "\n",
    "Georgetown students fill out a project interest survey at the start of Foundations, which we then use to attempt to optimize project teams curation. This serves as an intereting icebreaker to get people talking together about potential projects, but also as a mechanism to show optimization techniques in real life. Though obviously this method is more for demonstration purposes, I think it highlights a few key techniques. \n",
    "\n",
    "The optimization works as follows:\n",
    "\n",
    "1. Assign students into random teams. \n",
    "2. Compute the _cost_ of those team assignments across the entire cohort (cost function to follow). \n",
    "3. Select a random number of swaps between 10 and 100\n",
    "4. For each swap, switch two members of teams, if resulting _cost_ is less, continue; otherwise revert to original\n",
    "5. Repeat steps 2-4 until minimum error or maximum searches\n",
    "\n",
    "So basically this is a random hill climbing type search (or is intended to be). There are a number of ways to improve this function of course, but it's for demonstration only. \n",
    "\n",
    "The cost function is as follows:\n",
    "\n",
    "1. Start with cost = 0 (perfect teams have no cost)\n",
    "2. Add the square difference of each team's size with the optimal team size \n",
    "3. Add the number of unique OS per team - 1 (e.g. same OS is zero cost) \n",
    "4. Add cost of missing roles (e.g. don't have a programmer on the team)\n",
    "5. Add domain alignment cost (similar domains selected is better)\n",
    "6. Add dataset alignment cost (similar datasets selected is better) \n",
    "\n",
    "\n",
    "## Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHORT = 16      # Set to change the cohort to analyze. \n",
    "TEAM_SIZE = 4   # Optimal number of members per team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields and Fixtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "FIXTURES = os.path.join(os.getcwd(),\"fixtures\")\n",
    "\n",
    "FIELDS = {'name' : 'Name',\n",
    "          'email': 'Email',\n",
    "          'github': 'Github Username',\n",
    "          'linkedin': 'LinkedIn URL',\n",
    "          'os': 'What is your preferred operating system?',\n",
    "          'language': 'What programming languages are you familiar with?',\n",
    "          'python': 'What is your level of Python proficiency?',\n",
    "          'sql': 'What is your level of SQL proficiency?',\n",
    "          'cli': 'What is your proficiency with the command line?',\n",
    "          'dbs': 'What databases have you used before?',\n",
    "          'role': 'Which of these roles would you like your primary contribution on the team to be?',\n",
    "          'coord': 'Would you be willing to be a team coordinator?',\n",
    "          'project': 'At what level do you feel your overall project should be at?',\n",
    "          'domains': 'What domains are you interested in?',\n",
    "          'datasets': 'What types of projects/data sets are you interested in?'\n",
    "    }\n",
    "\n",
    "PROG_ROLE  = 'Programmer - focused on the technical implementation'\n",
    "STATS_ROLE = 'Statistician - focused on modeling and analysis'\n",
    "DOM_ROLE   = 'Domain Expert - focused on finding novel data products for specific data sets'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCohortPath(cohort=COHORT):\n",
    "    \"\"\"\n",
    "    Returns the path to the Cohort file in the fixtures directory.\n",
    "    \"\"\"\n",
    "    return os.path.join(FIXTURES,\"cohort{}-preferences.csv\".format(cohort))\n",
    "\n",
    "\n",
    "def loadData(cohort=COHORT):\n",
    "    \"\"\"\n",
    "    Loads and parses survey data. \n",
    "    \"\"\"\n",
    "    with open(getCohortPath(cohort), 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            row[FIELDS['language']] = parseMulti(row[FIELDS['language']])\n",
    "            row[FIELDS['python']] = parseInt(row[FIELDS['python']])\n",
    "            row[FIELDS['sql']] = parseInt(row[FIELDS['sql']])\n",
    "            row[FIELDS['cli']] = parseInt(row[FIELDS['cli']])\n",
    "            row[FIELDS['dbs']] = parseMulti(row[FIELDS['dbs']])\n",
    "            row[FIELDS['coord']] = parseBool(row[FIELDS['coord']])\n",
    "            row[FIELDS['project']] = parseInt(row[FIELDS['project']])\n",
    "            row[FIELDS['domains']] = parseMulti(row[FIELDS['domains']])\n",
    "            row[FIELDS['datasets']] = parseMulti(row[FIELDS['datasets']])\n",
    "            yield dict([(field, row[FIELDS[field]]) for field in FIELDS])\n",
    "                   \n",
    "def parseBool(s):\n",
    "    \"\"\"\n",
    "    Helper function for parsing yes/no/maybe. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        return {'yes': True,\n",
    "                'no': False,\n",
    "                'not sure': None,\n",
    "                'if i have to': None\n",
    "        }[s.lower()]\n",
    "    except KeyError: \n",
    "        return None\n",
    "\n",
    "def parseMulti(s):\n",
    "    \"\"\"\n",
    "    Helper function for parsing survey lists (checkboxes). \n",
    "    \"\"\"\n",
    "    return filter(lambda i: i != '', [i.strip() for i in s.split(',')])\n",
    "\n",
    "def parseInt(s):\n",
    "    \"\"\"\n",
    "    Helper function for parsing integer fields. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Teams Collection \n",
    "\n",
    "A collection of teams and computation of team cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cohort(object):\n",
    "    \n",
    "    def __init__(self, cohort=COHORT):\n",
    "        self.teams = defaultdict(list)\n",
    "        \n",
    "        # Assign students to ordered teams.\n",
    "        students = list(loadData(cohort))\n",
    "        n_teams  = (len(students) / TEAM_SIZE)\n",
    "        \n",
    "        for idx, student in enumerate(students):\n",
    "            self.teams[(idx + 1) / n_teams].append(student)\n",
    "    \n",
    "    def swap(self, source=None, target=None, sidx=None, tidx=None, transfer=False):\n",
    "        \"\"\"\n",
    "        Swaps two students between two teams. If None values are passed,\n",
    "        then the values are randomly selected. If transfer is true, then simply\n",
    "        transfer the source to the target, don't swap. \n",
    "        \"\"\"\n",
    "        if source is None:\n",
    "            source = random.choice(self.teams.keys())\n",
    "        \n",
    "        if target is None:\n",
    "            target = random.choice(self.teams.keys())\n",
    "        \n",
    "        if sidx is None and len(self.teams[source]) > 1:\n",
    "            sidx = random.randint(0, len(self.teams[source])-1)\n",
    "\n",
    "        if tidx is None and len(self.teams[target]) > 1:\n",
    "            tidx = random.randint(0, len(self.teams[target])-1)\n",
    "        \n",
    "        if sidx is not None:\n",
    "            alpha = self.teams[source].pop(sidx)\n",
    "            self.teams[target].append(alpha)\n",
    "        \n",
    "        if not transfer and tidx is not None:\n",
    "            bravo = self.teams[target].pop(tidx)\n",
    "            self.teams[source].append(bravo)\n",
    "    \n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        Computes the cost of the current team make up. \n",
    "        \"\"\"\n",
    "        cost = 0 # Perfect teams would have a cost of zero. \n",
    "        \n",
    "        # Loop over each team to compute the costs.\n",
    "        for team, prefs in self.teams.iteritems():\n",
    "        \n",
    "            # First add square difference in team size to optimal team size. \n",
    "            cost += (len(prefs) - TEAM_SIZE) ** 2\n",
    "            \n",
    "            # Add cost of multiple operating systems (1 OS is zero cost)\n",
    "            cost += (len(set([pref['os'] for pref in prefs])) - 1)\n",
    "            \n",
    "            # Add cost of missing roles \n",
    "            cost += 3 - len(set([pref['role'] for pref in prefs]))\n",
    "            \n",
    "            # Add cost of domain mis-alignment \n",
    "            domains = Counter(chain(*[domain for domain in [pref['domains'] for pref in prefs]]))\n",
    "            domains = domains.most_common(1)\n",
    "            if domains:\n",
    "                _, count = domains[0]\n",
    "                cost += len(prefs) - count \n",
    "            else:\n",
    "                cost += 99\n",
    "            \n",
    "            # Add cost of dataset mis-alignment\n",
    "            datasets = Counter(chain(*[dataset for dataset in [pref['datasets'] for pref in prefs]]))\n",
    "            datasets = datasets.most_common(1)\n",
    "            if datasets:\n",
    "                _, count = datasets[0]\n",
    "                cost += len(prefs) - count \n",
    "            else:\n",
    "                cost += 99\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def select_coordinator(self, teamno):\n",
    "        \"\"\"\n",
    "        From the people who selected yes to being coordinator, choose random.\n",
    "        \"\"\"\n",
    "        # Filter out people who didn't say yes to coordinator role.\n",
    "        coords = filter(\n",
    "            lambda p: p['coord'] in (True, None), \n",
    "            self.teams[teamno]\n",
    "        )\n",
    "\n",
    "        return random.choice(coords)['name']\n",
    "\n",
    "\n",
    "    def mean_level(self, teamno, field):\n",
    "        \"\"\"\n",
    "        Compute the mean level of the given numeric field.\n",
    "        \"\"\"\n",
    "        levels = [\n",
    "            float(pref[field]) if pref[field] else 0.0\n",
    "            for pref in self.teams[teamno]\n",
    "        ]\n",
    "\n",
    "        return sum(levels) / len(levels)\n",
    "    \n",
    "\n",
    "    def print_team(self, teamno):\n",
    "        # Create output structure\n",
    "        output = []\n",
    "\n",
    "        # Create Title Header\n",
    "        title = \"Team {} Selection Report\".format(teamno)\n",
    "        output.append(title)\n",
    "        output.append(\"-\"*len(title))\n",
    "        output.append(\"\")\n",
    "\n",
    "        # Print out averages\n",
    "        output.append(\n",
    "            \"  * Coordinator: {}\".format(self.select_coordinator(teamno))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "        output.append(\n",
    "            \"  * Mean Python Level: {}\".format(\n",
    "                self.mean_level(teamno, 'python')\n",
    "            )\n",
    "        )\n",
    "        output.append(\n",
    "            \"  * Mean SQL Level: {}\".format(\n",
    "                self.mean_level(teamno, 'sql')\n",
    "            )\n",
    "        )\n",
    "        output.append(\n",
    "            \"  * Mean CLI Level: {}\".format(\n",
    "                self.mean_level(teamno, 'cli')\n",
    "            )\n",
    "        )\n",
    "        output.append(\n",
    "            \"  * Mean Project Level: {}\".format(\n",
    "                self.mean_level(teamno, 'project')\n",
    "            )\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "        # Print out member names\n",
    "        output.append(\"  - Members:\")\n",
    "        output.extend([\n",
    "            \"    + {} ({})\".format(pref['name'], pref['email']) \n",
    "            for pref in self.teams[teamno]\n",
    "        ])\n",
    "        output.append(\"\")\n",
    "\n",
    "        # Print out domain preferences\n",
    "        domains = Counter(chain(*[domain for domain in [pref['domains'] for pref in self.teams[teamno]]]))\n",
    "        output.append(\"  - Domains:\")\n",
    "        output.extend([\n",
    "            \"    + {}: {}\".format(*prefs) \n",
    "            for prefs in domains.most_common()\n",
    "        ])\n",
    "        output.append(\"\")\n",
    "\n",
    "        # Print out project preferences\n",
    "        datasets = Counter(chain(*[dataset for dataset in [pref['datasets'] for pref in self.teams[teamno]]]))\n",
    "        output.append(\"  - Project Types:\")\n",
    "        output.extend([\n",
    "            \"    + {}: {}\".format(*prefs) \n",
    "            for prefs in datasets.most_common()\n",
    "        ])\n",
    "        output.append(\"\")\n",
    "\n",
    "        # Return report string\n",
    "        return \"\\n\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "cohort = Cohort()\n",
    "print cohort.cost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Team 0 Selection Report\n",
      "-----------------------\n",
      "\n",
      "  * Coordinator: Kalev Jaakson\n",
      "\n",
      "  * Mean Python Level: 5.66666666667\n",
      "  * Mean SQL Level: 4.33333333333\n",
      "  * Mean CLI Level: 3.0\n",
      "  * Mean Project Level: 3.33333333333\n",
      "\n",
      "  - Members:\n",
      "    + Jack  Harmon (john.harmon96@gmail.com)\n",
      "    + Samantha Sadiv (sadiv28@gmail.com)\n",
      "    + Kalev Jaakson (kj499@georgetown.edu)\n",
      "\n",
      "  - Domains:\n",
      "    + Agriculture: 3\n",
      "    + Sports: 2\n",
      "    + Transportation: 1\n",
      "    + Retail/Industry: 1\n",
      "    + Energy: 1\n",
      "    + Health Care/Medicine: 1\n",
      "    + Education: 1\n",
      "    + Government/Social Data: 1\n",
      "\n",
      "  - Project Types:\n",
      "    + Time Series Analysis: 3\n",
      "    + Visualization/Visual Analytics: 3\n",
      "    + Regression Analysis: 2\n",
      "    + Statistical Modeling for Forecasting: 2\n",
      "    + Clustering or Classification: 2\n",
      "    + Text Analysis/Natural Language Processing: 2\n",
      "    + Network Analysis: 1\n",
      "\n",
      "\n",
      "\n",
      "Team 1 Selection Report\n",
      "-----------------------\n",
      "\n",
      "  * Coordinator: Lisa Huynh\n",
      "\n",
      "  * Mean Python Level: 3.75\n",
      "  * Mean SQL Level: 4.75\n",
      "  * Mean CLI Level: 3.75\n",
      "  * Mean Project Level: 3.25\n",
      "\n",
      "  - Members:\n",
      "    + Lisa Huynh (lisathuynh92@gmail.com)\n",
      "    + Yifei Dong (yd144@georgetown.edu)\n",
      "    + Marc Rivera (rivera.marc.edward@gmail.com)\n",
      "    + Saba Shaikh (saba.shaikh2555@gmail.com)\n",
      "\n",
      "  - Domains:\n",
      "    + Government/Social Data: 4\n",
      "    + Finance/Banking: 3\n",
      "    + Sports: 2\n",
      "    + Human Behavior: 1\n",
      "    + Transportation: 1\n",
      "    + Retail/Industry: 1\n",
      "    + Security: 1\n",
      "    + Energy: 1\n",
      "    + facial recognization: 1\n",
      "    + Law/Intellectual Property: 1\n",
      "    + Social: 1\n",
      "    + Health Care/Medicine: 1\n",
      "\n",
      "  - Project Types:\n",
      "    + Statistical Modeling for Forecasting: 4\n",
      "    + Time Series Analysis: 3\n",
      "    + Text Analysis/Natural Language Processing: 3\n",
      "    + Visualization/Visual Analytics: 2\n",
      "    + Regression Analysis: 2\n",
      "    + Network Analysis: 1\n",
      "    + Clustering or Classification: 1\n",
      "\n",
      "\n",
      "\n",
      "Team 2 Selection Report\n",
      "-----------------------\n",
      "\n",
      "  * Coordinator: Mike\n",
      "\n",
      "  * Mean Python Level: 3.5\n",
      "  * Mean SQL Level: 5.0\n",
      "  * Mean CLI Level: 3.5\n",
      "  * Mean Project Level: 4.5\n",
      "\n",
      "  - Members:\n",
      "    + Zhonghao Zhao (zhaozhon93@gmail.com)\n",
      "    + Mike (dcu.mdmanley@gmail.com)\n",
      "\n",
      "  - Domains:\n",
      "    + Health Care/Medicine: 2\n",
      "    + Finance/Banking: 2\n",
      "    + Transportation: 1\n",
      "    + Retail/Industry: 1\n",
      "    + Energy: 1\n",
      "    + Sports: 1\n",
      "    + Government/Social Data: 1\n",
      "\n",
      "  - Project Types:\n",
      "    + Network Analysis: 2\n",
      "    + Regression Analysis: 2\n",
      "    + Statistical Modeling for Forecasting: 2\n",
      "    + Clustering or Classification: 2\n",
      "    + Time Series Analysis: 1\n",
      "    + Text Analysis/Natural Language Processing: 1\n",
      "\n",
      "\n",
      "\n",
      "Team 3 Selection Report\n",
      "-----------------------\n",
      "\n",
      "  * Coordinator: Chuck Cao\n",
      "\n",
      "  * Mean Python Level: 3.5\n",
      "  * Mean SQL Level: 3.0\n",
      "  * Mean CLI Level: 2.5\n",
      "  * Mean Project Level: 3.0\n",
      "\n",
      "  - Members:\n",
      "    + Ernest K. Kwegyir-Afful (Kobena.Afful@gmail.com)\n",
      "    + Paul Park (ppark25@gmail.com)\n",
      "    + Tarsha Eads (le239@georgetown.edu)\n",
      "    + Chuck Cao (chuckcao88@gmail.com)\n",
      "\n",
      "  - Domains:\n",
      "    + Government/Social Data: 4\n",
      "    + Health Care/Medicine: 3\n",
      "    + Education: 3\n",
      "    + Sports: 3\n",
      "    + Transportation: 2\n",
      "    + Retail/Industry: 2\n",
      "    + Finance/Banking: 2\n",
      "    + Agriculture: 1\n",
      "    + Energy: 1\n",
      "    + Security: 1\n",
      "\n",
      "  - Project Types:\n",
      "    + Regression Analysis: 4\n",
      "    + Visualization/Visual Analytics: 4\n",
      "    + Clustering or Classification: 4\n",
      "    + Text Analysis/Natural Language Processing: 4\n",
      "    + Statistical Modeling for Forecasting: 2\n",
      "    + Network Analysis: 1\n",
      "    + Time Series Analysis: 1\n",
      "    + Rule/Association Mining: 1\n",
      "\n",
      "\n",
      "\n",
      "Team 4 Selection Report\n",
      "-----------------------\n",
      "\n",
      "  * Coordinator: Mehmet Fatih Ogut\n",
      "\n",
      "  * Mean Python Level: 3.0\n",
      "  * Mean SQL Level: 4.66666666667\n",
      "  * Mean CLI Level: 2.0\n",
      "  * Mean Project Level: 2.33333333333\n",
      "\n",
      "  - Members:\n",
      "    + Lisa Schreiber (ls1349@georgetown.edu)\n",
      "    + Terry Tsao (wobee19@hotmail.com)\n",
      "    + Mehmet Fatih Ogut (fatihogut27@gmail.com)\n",
      "\n",
      "  - Domains:\n",
      "    + Retail/Industry: 3\n",
      "    + Transportation: 1\n",
      "    + Sports: 1\n",
      "    + Health Care/Medicine: 1\n",
      "    + Finance/Banking: 1\n",
      "    + Education: 1\n",
      "    + Government/Social Data: 1\n",
      "\n",
      "  - Project Types:\n",
      "    + Visualization/Visual Analytics: 3\n",
      "    + Statistical Modeling for Forecasting: 2\n",
      "    + Network Analysis: 1\n",
      "    + Regression Analysis: 1\n",
      "    + Clustering or Classification: 1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Search Method\n",
    "cohort = Cohort()\n",
    "\n",
    "for _ in xrange(5000):\n",
    "    # 100k searches \n",
    "    num_swaps = random.randint(10, 100)\n",
    "    prob_xfer = 0.25 \n",
    "    ncohort = Cohort()\n",
    "    \n",
    "    for _ in xrange(num_swaps):\n",
    "        xfer = True if random.random() <= prob_xfer else False \n",
    "        ncohort.swap(transfer=xfer)\n",
    "        if ncohort.cost() < cohort.cost():\n",
    "            cohort = ncohort\n",
    "        \n",
    "\n",
    "# Loop over each team to compute the costs.\n",
    "print cohort.cost()\n",
    "for team in cohort.teams:\n",
    "    print cohort.print_team(team)\n",
    "    print\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
